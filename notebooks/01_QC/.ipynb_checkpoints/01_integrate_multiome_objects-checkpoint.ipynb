{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5faa51fc-b01f-409f-9eea-e0e4db88460f",
   "metadata": {},
   "source": [
    "## Notebook to integrate multiome objects (Seurat/Signac)\n",
    "\n",
    "- Last updated: 02/06/2024\n",
    "- Author: Yang-Joon Kim\n",
    "\n",
    "- Step 1. load the multiome objects from all timepoints (6 timepoints, 2 replicates from 15-somites)\n",
    "- Step 2. integrate the RNA objects (seurat integration using rPCA or CCA)\n",
    "- Step 3. re-process the ATAC objects (merging peaks, re-computing the count matrices, then re-computing the PCA/LSI/SVD, seurat integration).\n",
    "- Step 4. (optional - another notebook) alignUMAP for individual timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af0603d5-288e-4cc6-a407-c26834dae091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered S3 method overwritten by 'SeuratDisk':\n",
      "  method            from  \n",
      "  as.sparse.H5Group Seurat\n",
      "\n",
      "Loading required package: BiocGenerics\n",
      "\n",
      "\n",
      "Attaching package: ‘BiocGenerics’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    anyDuplicated, aperm, append, as.data.frame, basename, cbind,\n",
      "    colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find,\n",
      "    get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply,\n",
      "    match, mget, order, paste, pmax, pmax.int, pmin, pmin.int,\n",
      "    Position, rank, rbind, Reduce, rownames, sapply, setdiff, sort,\n",
      "    table, tapply, union, unique, unsplit, which.max, which.min\n",
      "\n",
      "\n",
      "Loading required package: S4Vectors\n",
      "\n",
      "Loading required package: stats4\n",
      "\n",
      "\n",
      "Attaching package: ‘S4Vectors’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:Matrix’:\n",
      "\n",
      "    expand, unname\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "    findMatches\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    expand.grid, I, unname\n",
      "\n",
      "\n",
      "Loading required package: IRanges\n",
      "\n",
      "Loading required package: BSgenome\n",
      "\n",
      "Loading required package: GenomicRanges\n",
      "\n",
      "Loading required package: Biostrings\n",
      "\n",
      "Loading required package: XVector\n",
      "\n",
      "\n",
      "Attaching package: ‘Biostrings’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    strsplit\n",
      "\n",
      "\n",
      "Loading required package: rtracklayer\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               _                           \n",
      "platform       x86_64-pc-linux-gnu         \n",
      "arch           x86_64                      \n",
      "os             linux-gnu                   \n",
      "system         x86_64, linux-gnu           \n",
      "status                                     \n",
      "major          4                           \n",
      "minor          3.2                         \n",
      "year           2023                        \n",
      "month          10                          \n",
      "day            31                          \n",
      "svn rev        85441                       \n",
      "language       R                           \n",
      "version.string R version 4.3.2 (2023-10-31)\n",
      "nickname       Eye Holes                   \n",
      "[1] ‘4.4.0’\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre class=language-r><code>structure(function (..., envir = parent.frame()) \n",
       "{\n",
       "<span style=white-space:pre-wrap>    future &lt;- SequentialFuture(..., envir = envir)</span>\n",
       "<span style=white-space:pre-wrap>    if (!future$lazy) </span>\n",
       "<span style=white-space:pre-wrap>        future &lt;- run(future)</span>\n",
       "<span style=white-space:pre-wrap>    invisible(future)</span>\n",
       "}, class = c(\"FutureStrategy\", \"sequential\", \"uniprocess\", \"future\", \n",
       "\"function\"))</code></pre>"
      ],
      "text/latex": [
       "\\begin{minted}{r}\n",
       "structure(function (..., envir = parent.frame()) \n",
       "\\{\n",
       "    future <- SequentialFuture(..., envir = envir)\n",
       "    if (!future\\$lazy) \n",
       "        future <- run(future)\n",
       "    invisible(future)\n",
       "\\}, class = c(\"FutureStrategy\", \"sequential\", \"uniprocess\", \"future\", \n",
       "\"function\"))\n",
       "\\end{minted}"
      ],
      "text/markdown": [
       "```r\n",
       "structure(function (..., envir = parent.frame()) \n",
       "{\n",
       "    future <- SequentialFuture(..., envir = envir)\n",
       "    if (!future$lazy) \n",
       "        future <- run(future)\n",
       "    invisible(future)\n",
       "}, class = c(\"FutureStrategy\", \"sequential\", \"uniprocess\", \"future\", \n",
       "\"function\"))\n",
       "```"
      ],
      "text/plain": [
       "sequential:\n",
       "- args: function (..., envir = parent.frame())\n",
       "- tweaked: FALSE\n",
       "- call: NULL"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre class=language-r><code>structure(function (..., workers = 8, envir = parent.frame()) \n",
       "strategy(..., workers = workers, envir = envir), class = c(\"FutureStrategy\", \n",
       "\"tweaked\", \"multicore\", \"multiprocess\", \"future\", \"function\"), call = plan(\"multicore\", \n",
       "<span style=white-space:pre-wrap>    workers = 8))</span></code></pre>"
      ],
      "text/latex": [
       "\\begin{minted}{r}\n",
       "structure(function (..., workers = 8, envir = parent.frame()) \n",
       "strategy(..., workers = workers, envir = envir), class = c(\"FutureStrategy\", \n",
       "\"tweaked\", \"multicore\", \"multiprocess\", \"future\", \"function\"), call = plan(\"multicore\", \n",
       "    workers = 8))\n",
       "\\end{minted}"
      ],
      "text/markdown": [
       "```r\n",
       "structure(function (..., workers = 8, envir = parent.frame()) \n",
       "strategy(..., workers = workers, envir = envir), class = c(\"FutureStrategy\", \n",
       "\"tweaked\", \"multicore\", \"multiprocess\", \"future\", \"function\"), call = plan(\"multicore\", \n",
       "    workers = 8))\n",
       "```"
      ],
      "text/plain": [
       "multicore:\n",
       "- args: function (..., workers = 8, envir = parent.frame())\n",
       "- tweaked: TRUE\n",
       "- call: plan(\"multicore\", workers = 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the libraries\n",
    "suppressMessages(library(Seurat))\n",
    "suppressMessages(library(Signac))\n",
    "library(SeuratData)\n",
    "library(SeuratDisk)\n",
    "library(Matrix)\n",
    "\n",
    "# genome info\n",
    "library(GenomeInfoDb)\n",
    "library(ggplot2)\n",
    "library(patchwork)\n",
    "library(stringr)\n",
    "library(BSgenome.Drerio.UCSC.danRer11)\n",
    "\n",
    "print(R.version)\n",
    "print(packageVersion(\"Seurat\"))\n",
    "\n",
    "# parallelization in Signac: https://stuartlab.org/signac/articles/future\n",
    "library(future)\n",
    "plan()\n",
    "\n",
    "plan(\"multicore\", workers = 8)\n",
    "plan()\n",
    "\n",
    "# set the max memory size for the future\n",
    "options(future.globals.maxSize = 80 * 1024 ^ 3) # for 80 Gb RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9560c91d-91ae-4a43-b738-0d582b5ec414",
   "metadata": {},
   "source": [
    "## Step 1. Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea08735e-05ad-4098-80fb-38cf1607b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all seurat objects\n",
    "TDR118 <- readRDS(\"/hpc/projects/data.science/yangjoon.kim/zebrahub_multiome/data/processed_data/01_Signac_processed/TDR118reseq/TDR118_processed.RDS\")\n",
    "TDR119 <- readRDS(\"/hpc/projects/data.science/yangjoon.kim/zebrahub_multiome/data/processed_data/01_Signac_processed/TDR119reseq/TDR119_processed.RDS\")\n",
    "TDR124 <- readRDS(\"/hpc/projects/data.science/yangjoon.kim/zebrahub_multiome/data/processed_data/01_Signac_processed/TDR124reseq/TDR124_processed.RDS\")\n",
    "TDR125 <- readRDS(\"/hpc/projects/data.science/yangjoon.kim/zebrahub_multiome/data/processed_data/01_Signac_processed/TDR125reseq/TDR125_processed.RDS\")\n",
    "TDR126 <- readRDS(\"/hpc/projects/data.science/yangjoon.kim/zebrahub_multiome/data/processed_data/01_Signac_processed/TDR126/TDR126_processed.RDS\")\n",
    "TDR127 <- readRDS(\"/hpc/projects/data.science/yangjoon.kim/zebrahub_multiome/data/processed_data/01_Signac_processed/TDR127/TDR127_processed.RDS\")\n",
    "TDR128 <- readRDS(\"/hpc/projects/data.science/yangjoon.kim/zebrahub_multiome/data/processed_data/01_Signac_processed/TDR128/TDR128_processed.RDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "177bb669-7f5e-40e2-805e-44d5257d9b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChromatinAssay data with 248320 features for 13614 cells\n",
       "Variable features: 0 \n",
       "Genome: GRCz11 \n",
       "Annotation present: TRUE \n",
       "Motifs present: FALSE \n",
       "Fragment files: 1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TDR118[[\"ATAC\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01428aec-aa63-47ca-9212-c905d1709255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChromatinAssay data with 485357 features for 13614 cells\n",
       "Variable features: 485357 \n",
       "Genome: GRCz11 \n",
       "Annotation present: TRUE \n",
       "Motifs present: FALSE \n",
       "Fragment files: 1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TDR118[[\"peaks_merged\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4bd2b06-a746-4647-8b93-f5b5d8aad6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract only \"ATAC\" modality for simpler processing\n",
    "TDR118_ATAC <- TDR118[[\"peaks_merged\"]]\n",
    "TDR119_ATAC <- TDR119[[\"peaks_merged\"]]\n",
    "TDR124_ATAC <- TDR124[[\"peaks_merged\"]]\n",
    "TDR125_ATAC <- TDR125[[\"peaks_merged\"]]\n",
    "TDR126_ATAC <- TDR126[[\"peaks_merged\"]]\n",
    "TDR127_ATAC <- TDR127[[\"peaks_merged\"]]\n",
    "TDR128_ATAC <- TDR128[[\"peaks_merged\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38d4936-c1d0-414a-9490-fd75165a1cda",
   "metadata": {},
   "source": [
    "## Step 2. Integrate ATAC modality\n",
    "\n",
    "The first step in ATAC data integration is creating a common peak set. \n",
    "Description from Signac (https://stuartlab.org/signac/0.2/articles/merging):\n",
    "\n",
    "If the peaks were identified independently in each experiment then they will likely not overlap perfectly. We can merge peaks from all the datasets to create a common peak set, and quantify this peak set in each experiment prior to merging the objects.\n",
    "\n",
    "There are a few different ways that we can create a common peak set. One possibility is using the reduce or disjoin functions from the GenomicRanges package. The UnifyPeaks function extracts the peak coordinates from a list of objects and applies reduce or disjoin to the peak sets to create a single non-overlapping set of peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de0f57f6-ccfc-4bde-8fc1-93fa134fb9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRanges object with 640834 ranges and 0 metadata columns:\n",
       "           seqnames            ranges strand\n",
       "              <Rle>         <IRanges>  <Rle>\n",
       "       [1]        1            32-526      *\n",
       "       [2]        1         2372-3057      *\n",
       "       [3]        1         3427-4032      *\n",
       "       [4]        1         4469-7268      *\n",
       "       [5]        1         9541-9969      *\n",
       "       ...      ...               ...    ...\n",
       "  [640830]       25 37498106-37500090      *\n",
       "  [640831]       25 37500598-37500859      *\n",
       "  [640832]       25 37501104-37501839      *\n",
       "  [640833]       MT           22-3567      *\n",
       "  [640834]       MT       13233-16532      *\n",
       "  -------\n",
       "  seqinfo: 26 sequences from an unspecified genome; no seqlengths"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating a common peak set\n",
    "combined.peaks <- UnifyPeaks(object.list = list(TDR118_ATAC,TDR119_ATAC,TDR124_ATAC,\n",
    "                                                TDR125_ATAC,TDR126_ATAC,TDR127_ATAC,\n",
    "                                                TDR128_ATAC), mode = \"reduce\")\n",
    "combined.peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a97f86-c609-4eb3-9fbf-1c6d84e77457",
   "metadata": {},
   "source": [
    "### Step 2-2. quantify peaks in each dataset (re-process the count matrices)\n",
    "\n",
    "Using the re-defined peak set, we will re-compute the count matrices (cells-by-peaks).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db08be1f-d43e-480f-9317-0bf5597d9d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f5b0f1b-1079-4356-ab61-770a14f8f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to quantify the peaks\n",
    "recompute_count_matrices <- function(seurat_obj, combined.peaks, data_id){\n",
    "    new.counts <- FeatureMatrix(\n",
    "      fragments = Fragments(seurat_obj),\n",
    "      features = combined.peaks,\n",
    "      sep = c(\":\", \"-\"),\n",
    "      cells = colnames(seurat_obj)\n",
    "    )\n",
    "    seurat_obj[[\"peaks_integreated\"]] <- CreateAssayObject(counts = new.counts)\n",
    "    # add the data_id to the object\n",
    "    seurat_obj$dataset <- data_id\n",
    "    return(seurat_obj)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12752632-65cd-438c-bb2a-ba27561ad2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting reads overlapping genomic regions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "TDR118_ATAC <- recompute_count_matrices(TDR118_ATAC, combined.peaks = combined.peaks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a080d10-6812-4641-9fb6-bc42f4e1889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TDR118_ATAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91fb9abb-b267-49fa-84bf-18183d3680f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting reads overlapping genomic regions\n",
      "\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'seruat_obj' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'seruat_obj' not found\nTraceback:\n",
      "1. recompute_count_matrices(TDR118_ATAC, combined.peaks = combined.peaks)"
     ]
    }
   ],
   "source": [
    "# recompute the count matrices for each dataset, save as \"peaks_integrated\" ChromatinAssay\n",
    "TDR118_ATAC <- recompute_count_matrices(TDR118_ATAC, combined.peaks = combined.peaks)\n",
    "TDR119_ATAC <- recompute_count_matrices(TDR119_ATAC, combined.peaks = combined.peaks)\n",
    "TDR124_ATAC <- recompute_count_matrices(TDR124_ATAC, combined.peaks = combined.peaks)\n",
    "TDR125_ATAC <- recompute_count_matrices(TDR125_ATAC, combined.peaks = combined.peaks)\n",
    "TDR126_ATAC <- recompute_count_matrices(TDR126_ATAC, combined.peaks = combined.peaks)\n",
    "TDR127_ATAC <- recompute_count_matrices(TDR127_ATAC, combined.peaks = combined.peaks)\n",
    "TDR128_ATAC <- recompute_count_matrices(TDR128_ATAC, combined.peaks = combined.peaks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc08de31-0c02-4526-9977-c5e3c652e2b4",
   "metadata": {},
   "source": [
    "### merging all objects (concatenation of count matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6749036-5fe1-43be-a233-b0172559619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all datasets, adding a cell ID to make sure cell names are unique\n",
    "combined <- merge(x = TDR118_ATAC, \n",
    "                    y = list(TDR119_ATAC, TDR124_ATAC, TDR125_ATAC,\n",
    "                            TDR126_ATAC, TDR127_ATAC, TDR128_ATAC), \n",
    "                            add.cell.ids = c(\"TDR118\", \"TDR119\", \"TDR124\", \"TDR125\", \"TDR126\", \"TDR127\", \"TDR128\"))\n",
    "\n",
    "saveRDS(combined, \"/hpc/projects/data.science/yangjoon.kim/zebrahub_multiome/data/processed_data/01_Signac_processed/integrated_ATAC.RDS\")  # save the combined object\n",
    "print(\"Saved the combined object\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae917f4-3e42-4a42-ac40-534734c399ce",
   "metadata": {},
   "source": [
    "### computing dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a433fa-fd9d-41fe-9829-65df08a0752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to change to the assay containing common peaks\n",
    "DefaultAssay(combined) <- \"peaks_integrated\"\n",
    "combined <- RunTFIDF(combined)\n",
    "combined <- FindTopFeatures(combined, min.cutoff = 20)\n",
    "combined <- RunSVD(\n",
    "  combined,\n",
    "  reduction.key = 'LSI_',\n",
    "  reduction.name = 'lsi',\n",
    "  irlba.work = 400\n",
    ")\n",
    "combined <- RunUMAP(combined, dims = 2:30, reduction = 'lsi')\n",
    "\n",
    "# DimPlot(combined, group.by = 'dataset', pt.size = 0.1)\n",
    "\n",
    "saveRDS(combined, \"/hpc/projects/data.science/yangjoon.kim/zebrahub_multiome/data/processed_data/01_Signac_processed/integrated_ATAC.RDS\")  # save the combined object\n",
    "print(\"Saved the combined object with LSI and UMAP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf65ef-1d62-4c2c-90a3-016b8903eae1",
   "metadata": {},
   "source": [
    "## Step 3. Integrate RNA modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed09733a-36f8-4ea1-8a29-b7ddc9f7b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# extract the filename\n",
    "file <- file.list[[index]]\n",
    "\n",
    "# # convert the h5ad object to h5Seurat\n",
    "# seurat_obj_path <- Convert(file, dest = \"h5seurat\", overwrite=TRUE)\n",
    "\n",
    "# # read the h5Seurat format as a Seurat object\n",
    "# seurat_file <- LoadH5Seurat(seurat_obj_path, assays=\"RNA\")\n",
    "# seurat_file\n",
    "\n",
    "# Integration \n",
    "print(paste(\"Split object by timepoint\"))\n",
    "# 1. Split object and process each time point independently \n",
    "danio.list <- SplitObject(seurat_file, split.by='timepoint')\n",
    "\n",
    "# Filter out the timepoint where there are fewer than 10 cells\n",
    "# Create an empty list to store filtered Seurat objects\n",
    "filtered_danio_list <- list()\n",
    "\n",
    "# Loop through each Seurat object in danio.list\n",
    "for (timepoint in names(danio.list)) {\n",
    "    # Check if the number of samples (cells) is 10 or more\n",
    "    if (ncol(danio.list[[timepoint]]) >= 10) {\n",
    "        # If yes, add the Seurat object to the filtered list\n",
    "        filtered_danio_list[[timepoint]] <- danio.list[[timepoint]]\n",
    "    }\n",
    "}\n",
    "\n",
    "danio.list <- filtered_danio_list\n",
    "\n",
    "# find variable features\n",
    "danio.list <- lapply(X = danio.list, FUN = function(x) {\n",
    "    #x <- NormalizeData(x) # this dataset is already log-normalized\n",
    "    x <- FindVariableFeatures(x, selection.method = \"vst\", nfeatures = 2000)\n",
    "})\n",
    "\n",
    "features <- SelectIntegrationFeatures(object.list = danio.list)\n",
    "\n",
    "#     danio.list <- lapply(X = danio.list, FUN = function(x) {\n",
    "#         x <- ScaleData(x, features = features, verbose = FALSE)\n",
    "#         x <- RunPCA(x, features = features, verbose = FALSE)\n",
    "#     })\n",
    "# Adjust the number of PCs based on the number of cells\n",
    "# Finding the smallest number of cells in the datasets\n",
    "min_cells <- min(sapply(danio.list, ncol))\n",
    "\n",
    "# Setting the maximum number of PCA components\n",
    "max_pca_dims <- min(min_cells - 1, 30)\n",
    "\n",
    "# Setting the k.score (FindIntegrationAnchors)\n",
    "k.score_value <- min(round(min_cells/2), 30)\n",
    "\n",
    "danio.list <- lapply(X = danio.list, FUN = function(x) {\n",
    "    #num_cells <- ncol(x)\n",
    "    #num_pcs <- min(num_cells - 1, 30)  # Adjusting the number of PCs\n",
    "    x <- ScaleData(x, features = features, verbose = FALSE)\n",
    "    x <- RunPCA(x, features = features, npcs = max_pca_dims, verbose = FALSE)\n",
    "    return(x)\n",
    "})\n",
    "\n",
    "\n",
    "print(paste(\"Integration ... \"))\n",
    "# 2. Find integration anchors and integrate data \n",
    "#     # Get the index for the \"10hpf\" entry\n",
    "#     index_10hpf <- which(names(danio.list) == \"10hpf\")\n",
    "#     index_10hpf\n",
    "\n",
    "#     # Get the index for the \"10dpf\" entry\n",
    "#     index_10dpf <- which(names(danio.list) == \"10dpf\")\n",
    "#     index_10dpf\n",
    "danio.anchors <- FindIntegrationAnchors(object.list = danio.list, anchor.features = features,\n",
    "                                       normalization.method = 'LogNormalize', #c(\"LogNormalize\", \"SCT\"),\n",
    "                                       dims = 1:max_pca_dims, # default 1:30\n",
    "                                       k.anchor = 5, #default 5\n",
    "                                       k.filter = 200, #default 200 for a query cell, If the anchor reference cell is found within the first k.filter (200) neighbors, then we retain this anchor.\n",
    "                                       k.score = k.score_value, # default 30: For each reference anchor cell, we determine its k.score (30) nearest within-dataset neighbors and its k.score nearest neighbors in the query dataset\n",
    "                                       reduction = \"rpca\", # default cca, rpca should be faster \n",
    "                                       #reference = c(index_10hpf,index_10dpf) # the 10hpf and 10dpf timepoints as \"references\" that other datasets will be anchored against\n",
    "                                       )\n",
    "# Integreate the datasets using \"anchors\" computed above\n",
    "min_neighborhood = min(round(min_cells/2), 30)\n",
    "\n",
    "seurat_combined <- IntegrateData(anchorset = danio.anchors, \n",
    "                                new.assay.name = \"integrated\",\n",
    "                                dims=1:max_pca_dims,\n",
    "                                k.weight = min_neighborhood)\n",
    "\n",
    "# 3. Generate an integrated embedding: run PCA on integrated (corrected) counts \n",
    "# specify that we will perform downstream analysis on the corrected data note that the\n",
    "# original unmodified data still resides in the 'RNA' assay\n",
    "DefaultAssay(seurat_combined) <- \"integrated\"\n",
    "\n",
    "# Run the standard workflow for visualization and clustering\n",
    "seurat_combined <- ScaleData(seurat_combined, verbose = FALSE)\n",
    "seurat_combined <- RunPCA(seurat_combined, npcs = 100, verbose = FALSE)\n",
    "print(paste(\"Runnning UMAP on the integrated PCA embedding...\"))\n",
    "\n",
    "# 4. UMAP on integrated embbedding \n",
    "seurat_combined <- RunUMAP(seurat_combined, reduction = \"pca\", dims = 1:30,\n",
    "                             metric='euclidean',\n",
    "                             n.neighbors = 30,\n",
    "                             local.connectivity  =1, # 1 default\n",
    "                             repulsion.strength = 1, # 1 default\n",
    "                         )\n",
    "seurat_combined <- FindNeighbors(seurat_combined, reduction = \"pca\", dims = 1:30)\n",
    "seurat_combined <- FindClusters(seurat_combined, resolution = 0.5)\n",
    "\n",
    "print(paste(\"plotting UMAP with different batch keys...\"))\n",
    "# Check the integrated UMAP\n",
    "plot1 <- DimPlot(seurat_combined, dims = c(1, 2), group.by = \"timepoint\")\n",
    "plot2 <- DimPlot(seurat_combined, dims = c(1, 2), group.by = \"fish\")\n",
    "#plot3 <- DimPlot(seurat_combined, dims = c(1, 2), group.by = \"leiden\")\n",
    "plot1 + plot2 #+ plot3\n",
    "\n",
    "# 5. Export R object \n",
    "# name of the output file\n",
    "subset_celltype <- subset.name.list[[index]]\n",
    "saveRDS(seurat_combined, file = paste0(SCT_ATLAS, subset_celltype, \"_seurat_integrated.rds\")) \n",
    "print(paste(\"RDS object saved\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d98f1eb-b3e1-47d2-99db-acbb82640c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 4.3",
   "language": "R",
   "name": "ir43"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
