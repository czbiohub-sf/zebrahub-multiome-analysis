"""
To run on SLURM:
snakemake -j <number of jobs> \ 
    --cluster-config=cluster.yml \
    --cluster "sbatch --mem={cluster.mem} \
    --time {cluster.time} \
    --cpus-per-task {threads} \
    -o {cluster.output} -e {cluster.error}" \
    --use-singularity \
    --keep-going

last two parameters are for singularity for R/python components
keep-going is used if anything errors out, the job still continues to run
"""

# Define the target files, usually good practice
rule all:
    input:
        rds="{output_filepath}/{data_id}_processed.RDS",
        h5ad_rna="{output_filepath}/{data_id}_RNA.h5ad",
        h5ad_atac="{output_filepath}/{data_id}_ATAC.h5ad"

rule preprocess_multiome_data:
    input:
        #raw_data_path="{raw_data_path}",
        raw_data_path=config["raw_data_path"],
        gref=config["gref_path"]
    output:
        rds="{output_filepath}/{data_id}_processed.RDS",
        h5ad_rna="{output_filepath}/{data_id}_RNA.h5ad",
        h5ad_atac="{output_filepath}/{data_id}_ATAC.h5ad"
    params:
        reference=config["reference"],
        annotation_class=config["annotation_class"], # similarly for annotation_class if it's from the config
        script_path=config["01_script_path"]
    shell:
        """
        Rscript {params.script_path} {input.raw_data_path} {input.gref} {params.reference} {params.annotation_class} {output.rds} {wildcards.data_id}
        """